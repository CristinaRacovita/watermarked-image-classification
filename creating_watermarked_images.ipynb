{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529587c0-7e6c-4e97-8921-a6ed1297e8c1",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Creating Watermarked Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c34c73-3c11-49ed-a3cd-5a2b51253025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# set constants\n",
    "SEED = 19\n",
    "CLASSES_NO = 37\n",
    "\n",
    "# make the operations deterministic\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975e5ee3-1c1a-43d2-9d77-be68acde3c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_images_dataset(images_path):\n",
    "    image_files = [\n",
    "        f for f in os.listdir(images_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "    image_data = []\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        image_data.append(\n",
    "            {\"image_name\": image_file, \"image_path\": image_path, \"image_size\": img.size}\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8bd90-0cca-4be5-be7a-9911842e5b3c",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## [The Oxford-IIIT Pet Dataset](https://www.kaggle.com/datasets/tanlikesmath/the-oxfordiiit-pet-dataset)\n",
    "\n",
    "We need to resize the images if the Oxford-IIIT Pet dataset does not match the ones required for the image classifier. We plan to use either Tiny-Vit 5M or MobileViT-XXS 1.3M for image classification. Both of these models use images of 224x224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68eaf6f-b872-4c3c-b64c-5a736786c662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_oxford_pet_dataset():\n",
    "    return kagglehub.dataset_download(\"tanlikesmath/the-oxfordiiit-pet-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93275666-dc72-412e-9f98-bd33b481fcf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_oxford_pet_dataset():\n",
    "    path = load_oxford_pet_dataset()\n",
    "    images_path = f\"{path}/images\"\n",
    "    return read_images_dataset(images_path)\n",
    "\n",
    "\n",
    "oxford_pet_dataset = read_oxford_pet_dataset()\n",
    "oxford_pet_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ab1ce1-c484-4d45-8189-b294ebe6060f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image(image_path, dim):\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    new_size = (dim, dim)\n",
    "    resized_image = image.resize(new_size)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa5b08-5d00-4997-928e-88915eeee5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resize_image(oxford_pet_dataset[\"image_path\"][0], 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32e2b6",
   "metadata": {},
   "source": [
    "### Split the dataset into trainval-test folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca91ce3",
   "metadata": {},
   "source": [
    "This split is taken from [here](https://www.kaggle.com/datasets/julinmaloof/the-oxfordiiit-pet-dataset) and is the one recommended by the [authors](https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/parkhi12cat.pdf). Additionally, add the class information to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9133c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford_pet_dataset[\"image_name\"] = oxford_pet_dataset[\"image_name\"].map(\n",
    "    lambda x: x.replace(\".jpg\", \"\")\n",
    ")\n",
    "oxford_pet_dataset = oxford_pet_dataset.set_index(\"image_name\")\n",
    "oxford_pet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.read_csv(\"./data/test.txt\", delimiter=\" \", header=None)[[0, 1]]\n",
    "test_images[\"fold\"] = \"test\"\n",
    "\n",
    "trainval_images = pd.read_csv(\"./data/trainval.txt\", delimiter=\" \", header=None)[[0, 1]]\n",
    "trainval_images[\"fold\"] = \"trainval\"\n",
    "\n",
    "dataset_folds = (\n",
    "    pd.concat([test_images, trainval_images])\n",
    "    .rename({0: \"image_name\", 1: \"class\"}, axis=1)\n",
    "    .set_index(\"image_name\")\n",
    ")\n",
    "dataset_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b429a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_dataset_info = oxford_pet_dataset.join(dataset_folds, on=\"image_name\")\n",
    "pet_dataset_info = pet_dataset_info.dropna()\n",
    "pet_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ab0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_resize_oxford_pet_dataset(original_dataset, fold):\n",
    "    output_dir = f\"./data/resized_images/{fold}\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for _, row in original_dataset.iterrows():\n",
    "        input_image_path = row[\"image_path\"]\n",
    "        resized_image = resize_image(input_image_path, 224)\n",
    "\n",
    "        output_image_path = os.path.join(output_dir, row[\"image_name\"])\n",
    "        resized_image.save(output_image_path + \".jpg\")\n",
    "\n",
    "    return output_dir\n",
    "\n",
    "\n",
    "trainval_data = pet_dataset_info[pet_dataset_info[\"fold\"] == \"trainval\"].reset_index()\n",
    "resized_dataset_dir_path = save_resize_oxford_pet_dataset(trainval_data, \"trainval\")\n",
    "trainval_data[\"image_path\"] = trainval_data[\"image_path\"].map(\n",
    "    lambda x: f\"./data/resized_images/trainval/\" + x.split(\"\\\\\")[-1]\n",
    ")\n",
    "\n",
    "test_data = pet_dataset_info[pet_dataset_info[\"fold\"] == \"test\"].reset_index()\n",
    "resized_dataset_dir_path = save_resize_oxford_pet_dataset(test_data, \"test\")\n",
    "test_data[\"image_path\"] = test_data[\"image_path\"].map(\n",
    "    lambda x: f\"./data/resized_images/test/\" + x.split(\"\\\\\")[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_dataset_info = (\n",
    "    pd.concat([trainval_data, test_data]).set_index(\"image_name\").drop(\"image_size\", axis=1)\n",
    ")\n",
    "pet_dataset_info.to_csv(\"./data/pet_dataset_info.csv\")\n",
    "pet_dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012692f-68fa-47ea-87f0-a615b254f146",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## [QMUL-OpenLogo Dataset](https://hangsu0730.github.io/qmul-openlogo/)\n",
    "We need to edit the images in this dataset by converting them to grayscale, removing the background and applying a specified transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42ee28-4a21-465c-96f7-32e6c44e9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmul_openlogo_dataset = read_images_dataset(\"./data/qmul_openlogo_dataset\")\n",
    "\n",
    "# shuffle the rows so that we can take a random subset\n",
    "qmul_openlogo_dataset = qmul_openlogo_dataset.sample(frac=1, random_state=SEED).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "\n",
    "qmul_openlogo_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ec01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return image.convert(\"LA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5651f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_logo(image, max_size):\n",
    "    # resize an image to a maximum height or width by keeping the aspect ratio\n",
    "    if image.size[0] > image.size[1]:\n",
    "        new_size = (max_size, int(max_size * image.size[1] / image.size[0]))\n",
    "    else:\n",
    "        new_size = (int(max_size * image.size[0] / image.size[1]), max_size)\n",
    "\n",
    "    resized_image = image.resize(new_size)\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c6d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transpacency_mask(image_path, transparency):\n",
    "    # a threshold is needed to separate the logo from the background\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    # first, a Gaussian blur is applied to avoid rough edges\n",
    "    blurred_image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    # then the threshold is found using the Otsu's binarization method\n",
    "    _, thresholded = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # the background is set to 0 and the logo to the desired transparency\n",
    "    thresholded = (255 - thresholded) // 255 * transparency\n",
    "    mask = Image.fromarray(thresholded)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00d18047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transparency_adjusted_logo(image_path, transparency_value):\n",
    "    image = convert_to_grayscale(image_path)\n",
    "\n",
    "    # mask the image to remove the background and change transparency\n",
    "    transparency = int((1 - transparency_value) * 255)\n",
    "    mask = get_transpacency_mask(image_path, transparency)\n",
    "    image.putalpha(mask)\n",
    "\n",
    "    image = image.convert(\"RGBA\")\n",
    "    image = resize_logo(image, 224)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce13993-25fc-41b7-aa27-a76ef1339d14",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Creating the Final Dataset\n",
    "Each logo will be applied on the host image at a random position with a random size, rotation and transparency. Considering the related work, each logo should be placed on multiple images and the logos included in the trainval and test sets should be disjoint. Because the dataset will be classified, we impose the constraint that each logo should be hosted by at least n images from each class. This will help in making sure the logos are distributed evenly across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5301472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logos(pet_dataset_info, qmul_openlogo_dataset, class_images_per_logo):\n",
    "    trainval_logos_no = (\n",
    "        math.floor(\n",
    "            pet_dataset_info[pet_dataset_info[\"fold\"] == \"trainval\"].shape[0]\n",
    "            / CLASSES_NO\n",
    "            / class_images_per_logo\n",
    "        )\n",
    "        + 1\n",
    "    )\n",
    "\n",
    "    test_logos_no = (\n",
    "        math.floor(\n",
    "            pet_dataset_info[pet_dataset_info[\"fold\"] == \"test\"].shape[0]\n",
    "            / CLASSES_NO\n",
    "            / class_images_per_logo\n",
    "        )\n",
    "        + 1\n",
    "    )\n",
    "\n",
    "    trainval_logos = qmul_openlogo_dataset[:trainval_logos_no][\"image_path\"].to_list()\n",
    "    test_logos = qmul_openlogo_dataset[trainval_logos_no : trainval_logos_no + test_logos_no][\n",
    "        \"image_path\"\n",
    "    ].to_list()\n",
    "\n",
    "    return trainval_logos, test_logos\n",
    "\n",
    "\n",
    "trainval_logos_path, test_logos_path = get_logos(pet_dataset_info, qmul_openlogo_dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c6009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_logo(image_path, logo_path):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    tranparency_value = random.uniform(0.35, 0.6)\n",
    "    logo = get_transparency_adjusted_logo(logo_path, tranparency_value)\n",
    "\n",
    "    rotation = random.randint(-45, 45)\n",
    "    logo = logo.rotate(rotation, expand=True).resize((224, 224))\n",
    "\n",
    "    scaling_factor = random.uniform(0.6, 0.85)\n",
    "    logo = logo.resize(\n",
    "        (math.floor(logo.size[0] * scaling_factor), math.floor(logo.size[1] * scaling_factor))\n",
    "    )\n",
    "\n",
    "    position = (\n",
    "        random.randint(0, image.size[0] - logo.size[0]),\n",
    "        random.randint(0, image.size[1] - logo.size[1]),\n",
    "    )\n",
    "    image.paste(logo, position, logo)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b18362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_with_logos(fold, logos_path):\n",
    "    pet_dataset_fold = pet_dataset_info[pet_dataset_info[\"fold\"] == fold]\n",
    "    output_dir = f\"./data/images_with_logos/{fold}/\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for logo_path in logos_path:\n",
    "        images_for_logo = pet_dataset_fold.groupby(\"class\").head(3)\n",
    "        images_for_logo_paths = images_for_logo[\"image_path\"].to_list()\n",
    "\n",
    "        for image_for_logo_path in images_for_logo_paths:\n",
    "            image_with_logo = place_logo(image_for_logo_path, logo_path)\n",
    "            image_with_logo.save(output_dir + image_for_logo_path.split(\"/\")[-1])\n",
    "\n",
    "        pet_dataset_fold = pet_dataset_fold[~pet_dataset_fold.index.isin(images_for_logo.index)]\n",
    "\n",
    "    assert pet_dataset_fold.shape[0] == 0, \"Not all images have logos\"\n",
    "\n",
    "\n",
    "create_dataset_with_logos(\"trainval\", trainval_logos_path)\n",
    "create_dataset_with_logos(\"test\", test_logos_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WATERMARK_REMOVAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
