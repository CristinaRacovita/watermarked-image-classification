{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e10b32-7257-4b21-9b31-81951eeec608",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Implement IWRU-net for Watermark Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d831345a-d190-429f-803b-cb4b5b46c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# make the code deterministic\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a259938-378f-4186-8698-cb03a4aa081d",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Define the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c7efc9-c657-4b4b-a24d-86a2fb962f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    KERNEL_SIZE_CONV = 3\n",
    "    KERNEL_SIZE_MAX_POOLING = 2\n",
    "    PADDING = 1\n",
    "\n",
    "    def __init__(self, unet_channels_in, unet_channels_out):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        self.conv_relu_1 = self.conv_relu(unet_channels_in, 48)\n",
    "        self.conv_relu_pooling_2 = self.conv_relu_pooling(48, 48)\n",
    "        self.conv_relu_pooling_3 = self.conv_relu_pooling(48, 48)\n",
    "        self.conv_relu_pooling_4 = self.conv_relu_pooling(48, 48)\n",
    "        self.conv_relu_pooling_5 = self.conv_relu_pooling(48, 48)\n",
    "        self.conv_relu_pooling_6 = self.conv_relu_pooling(48, 48)\n",
    "\n",
    "        # bottleneck\n",
    "        self.conv_relu_pooling_7 = self.conv_relu_pooling(48, 48)\n",
    "\n",
    "        # decoder\n",
    "        self.conv_relu_convt8 = self.conv_relu_convt(96, 96)\n",
    "        self.conv_relu_9 = self.conv_relu(96, 96)\n",
    "        self.conv_relu_convt10 = self.conv_relu_convt(144, 96)\n",
    "        self.conv_relu11 = self.conv_relu(96, 96)  # the dimensions are not mentioned in the paper\n",
    "        self.conv_relu_convt12 = self.conv_relu_convt(144, 96)\n",
    "        self.conv_relu13 = self.conv_relu(96, 96)\n",
    "        self.conv_relu_convt14 = self.conv_relu_convt(144, 96)\n",
    "        self.conv_relu15 = self.conv_relu(96, 96)\n",
    "        self.conv_relu_convt16 = self.conv_relu_convt(144, 96)\n",
    "        self.conv_relu17 = self.conv_relu(96, 96)\n",
    "        self.conv_relu_convt18 = self.conv_relu_convt(99, 96)\n",
    "        self.conv_relu19 = self.conv_relu(96, 64) # in the paper it's written 99 instead on 94\n",
    "        self.conv_relu20 = self.conv_relu(64, 32)\n",
    "        self.conv_leaky_relu21 = self.conv_leaky_relu(32, unet_channels_out)\n",
    "\n",
    "    def conv_relu(self, channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=UNet.KERNEL_SIZE_CONV,\n",
    "                padding=UNet.PADDING\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def conv_leaky_relu(self, channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=UNet.KERNEL_SIZE_CONV,\n",
    "                padding=UNet.PADDING\n",
    "            ),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def conv_relu_pooling(self, channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=UNet.KERNEL_SIZE_CONV,\n",
    "                padding=UNet.PADDING\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(UNet.KERNEL_SIZE_MAX_POOLING),\n",
    "        )\n",
    "\n",
    "    def conv_relu_convt(self, channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=UNet.KERNEL_SIZE_CONV,\n",
    "                padding=UNet.PADDING\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(\n",
    "                channels_out,\n",
    "                channels_out,\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        enc1 = self.conv_relu_1(x)\n",
    "        enc2 = self.conv_relu_pooling_2(enc1)\n",
    "        enc3 = self.conv_relu_pooling_3(enc2)\n",
    "        enc4 = self.conv_relu_pooling_4(enc3)\n",
    "        enc5 = self.conv_relu_pooling_5(enc4)\n",
    "        enc6 = self.conv_relu_pooling_6(enc5)\n",
    "\n",
    "        # bottleneck\n",
    "        bottleneck7 = self.conv_relu_pooling_7(enc6)\n",
    "\n",
    "        # decoder\n",
    "        decoder8 = self.conv_relu_convt8(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    bottleneck7,\n",
    "                    F.interpolate(\n",
    "                        enc6,\n",
    "                        bottleneck7.size()[2:],\n",
    "                        mode=\"bilinear\",\n",
    "                        align_corners=True,\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder9 = self.conv_relu_9(decoder8)\n",
    "        decoder10 = self.conv_relu_convt10(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    decoder9,\n",
    "                    F.interpolate(\n",
    "                        enc5, decoder9.size()[2:], mode=\"bilinear\", align_corners=True\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder11 = self.conv_relu11(decoder10)\n",
    "        decoder12 = self.conv_relu_convt12(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    decoder11,\n",
    "                    F.interpolate(\n",
    "                        enc4, decoder11.size()[2:], mode=\"bilinear\", align_corners=True\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder13 = self.conv_relu13(decoder12)\n",
    "        decoder14 = self.conv_relu_convt14(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    decoder13,\n",
    "                    F.interpolate(\n",
    "                        enc3, decoder13.size()[2:], mode=\"bilinear\", align_corners=True\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder15 = self.conv_relu15(decoder14)\n",
    "        decoder16 = self.conv_relu_convt16(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    decoder15,\n",
    "                    F.interpolate(\n",
    "                        enc2, decoder15.size()[2:], mode=\"bilinear\", align_corners=True\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder17 = self.conv_relu17(decoder16)\n",
    "        decoder18 = self.conv_relu_convt18(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    decoder17,\n",
    "                    F.interpolate(\n",
    "                        x, decoder17.size()[2:], mode=\"bilinear\", align_corners=True\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        )\n",
    "        decoder19 = self.conv_relu19(decoder18)\n",
    "        decoder20 = self.conv_relu20(decoder19)\n",
    "\n",
    "        return self.conv_leaky_relu21(decoder20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6184fedd-3127-4cad-b999-b82abea88ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1504419 parameters\n"
     ]
    }
   ],
   "source": [
    "unet = UNet(3, 3)\n",
    "total_params = sum(layer.numel() for layer in unet.parameters())\n",
    "print(f\"The model has {total_params} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f71bd3c-b764-493d-8108-5ea3829c8efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 3, 256, 256)  # Example input\n",
    "output_tensor = unet(input_tensor)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158a56f-d0d5-4b1f-bca7-bdfa17ed48be",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Load images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
